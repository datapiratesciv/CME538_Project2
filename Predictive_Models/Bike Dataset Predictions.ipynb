{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyM7+4jF4OLxv1VHY5E44YjS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import holidays\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.linear_model import LinearRegression\n","from prophet import Prophet\n","\n","\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_percentage_error\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import r2_score\n","\n","pd.set_option('display.max_rows', None)"],"metadata":{"id":"6UI4zIotjfUO","executionInfo":{"status":"ok","timestamp":1670450104439,"user_tz":300,"elapsed":232,"user":{"displayName":"Ray Coden Mercurius","userId":"17162744304693628162"}}},"execution_count":252,"outputs":[]},{"cell_type":"code","source":["def load_bike_data():\n","  '''Returns DataFrame with cleaned bike usage data'''\n","  # Load Data\n","  trips_filenames = [filename for filename in os.listdir() if \"trips_data\" in filename]\n","  bike_data = pd.DataFrame()\n","  for file in trips_filenames:\n","    temp_df = pd.read_csv(file)\n","    bike_data = pd.concat([bike_data,temp_df])\n","\n","  bike_data[\"Start Time\"] = pd.DatetimeIndex(bike_data[\"Start Time\"].str[:-6]).tz_localize('EST')\n","  bike_data = bike_data.sort_values(by='Start Time').copy()\n","\n","  # turn time columns into index\n","  bike_data.index = bike_data[\"Start Time\"]\n","  bike_data = bike_data.drop(columns=[\"Start Time\"])\n","\n","  return bike_data\n"],"metadata":{"id":"CF5R-PYjwKUA","executionInfo":{"status":"ok","timestamp":1670450104676,"user_tz":300,"elapsed":5,"user":{"displayName":"Ray Coden Mercurius","userId":"17162744304693628162"}}},"execution_count":253,"outputs":[]},{"cell_type":"code","source":["def load_weather_data():\n","   '''Returns DataFrame with weather data'''\n","   weather_data = pd.read_csv(\"weather_data.csv\")\n","\n","    # filter columns\n","   weather_data = weather_data[[\"Date/Time\",\"Temp (°C)\",\"Wind Spd (km/h)\",\"Visibility (km)\",\"Weather\"]]\n","\n","   # add datetime as index\n","   weather_data.index = pd.DatetimeIndex(weather_data[\"Date/Time\"].str[:-6]).tz_localize('EST')\n","   weather_data = weather_data.sort_index()\n","   weather_data = weather_data.drop(columns=[\"Date/Time\"])\n","\n","   return weather_data"],"metadata":{"id":"3O29hOS_wb8v","executionInfo":{"status":"ok","timestamp":1670450104676,"user_tz":300,"elapsed":5,"user":{"displayName":"Ray Coden Mercurius","userId":"17162744304693628162"}}},"execution_count":254,"outputs":[]},{"cell_type":"code","source":["def drop_features(data,keep_columns=None,remove_columns=None):\n","  '''Returns dataframe with irrelevant columns filtered out'''\n","  if(remove_columns==None):\n","    return data[keep_columns]\n","  if(keep_columns==None):\n","    return data.drop(columns=remove_columns)\n","\n","def reduce_temporal_precision(data,time_interval=\"H\"):\n","  '''Returns dataframe with a more condensed time discritization'''\n","  data[\"num_trips\"] = np.ones(len(data))\n","  data = data.groupby(data['trip_start_time'].dt.floor(time_interval)).agg({'num_trips':'sum'})\n","  return data\n"],"metadata":{"id":"f_pBjRoVmN7-","executionInfo":{"status":"ok","timestamp":1670450104676,"user_tz":300,"elapsed":5,"user":{"displayName":"Ray Coden Mercurius","userId":"17162744304693628162"}}},"execution_count":255,"outputs":[]},{"cell_type":"code","source":["def add_temporal_features(data):\n","  '''Returns dataframe with new temporal features hand-crafted for prediction purposes'''\n","  # add the years since Jan 1,2017 (years can be decimal)\n","  basedate = pd.Timestamp('2017-01-01',tz=\"EST\")\n","  data[\"Years Since Start\"] = ((data.index.to_series() - basedate).dt.days)/(365*5)\n","\n","  # add the day of the year (normalized to 0-1)\n","  data[\"Day of Year\"] = (data.index.to_series().dt.dayofyear)/365\n","\n","  # add hour of day (normalized to 0-1)\n","  data[\"Hour of Day\"] = (data.index.to_series().dt.hour)/24\n","\n","  # day of week (normalized to 0-1)\n","  data[\"Day of Week\"] = (data.index.to_series().dt.dayofweek)/7\n","\n","  # is holiday\n","  holidays_list = holidays.Canada(years=[2017,2018,2019,2020,2021,2022])\n","  data[\"Is Holiday\"] = data.index.to_series().dt.date.apply(lambda x: x in holidays_list) \n","\n","  # is weekend\n","  data[\"Is Weekend\"] = data.index.to_series().dt.dayofweek>=5\n","\n","  return data"],"metadata":{"id":"Ls5CRDgmpRTt","executionInfo":{"status":"ok","timestamp":1670450104677,"user_tz":300,"elapsed":5,"user":{"displayName":"Ray Coden Mercurius","userId":"17162744304693628162"}}},"execution_count":256,"outputs":[]},{"cell_type":"code","source":["def add_weather_features(bike_data, weather_data):\n","  '''Returns dataframe with new weather features hand-crafted for prediction purposes'''\n","  # add weather columns\n","  filt = weather_data[\"Weather\"].isna()\n","  weather_data[\"Weather\"][filt] = \"Clear\"\n","  weather_data[\"Weather Clear\"] = weather_data[\"Weather\"].str.contains(\"Clear\")\n","  weather_data[\"Fog\"] = weather_data[\"Weather\"].str.contains(\"Fog\")\n","  weather_data[\"Rain\"] = weather_data[\"Weather\"].str.contains(\"Rain\")\n","  weather_data[\"Snow\"] = weather_data[\"Weather\"].str.contains(\"Snow\")\n","  weather_data = weather_data.drop(columns=[\"Weather\"])\n","\n","  # normalize numeric columns\n","  weather_data[\"Temp (°C)\"] = (weather_data[\"Temp (°C)\"]-weather_data[\"Temp (°C)\"].mean())/weather_data[\"Temp (°C)\"].std()\n","  weather_data[\"Wind Spd (km/h)\"] = (weather_data[\"Wind Spd (km/h)\"]-weather_data[\"Wind Spd (km/h)\"].mean())/weather_data[\"Wind Spd (km/h)\"].std()\n","  weather_data[\"Visibility (km)\"] = (weather_data[\"Visibility (km)\"]-weather_data[\"Visibility (km)\"].mean())/weather_data[\"Visibility (km)\"].std()\n","\n","  # clean missing values (CHANGE this to take the values of the nearest neighbors)\n","  print(\"Weather Temperature Missing\",sum(weather_data[\"Temp (°C)\"].isna()),\"values\")\n","  weather_data[\"Temp (°C)\"][weather_data[\"Temp (°C)\"].isna()] = weather_data[\"Temp (°C)\"].mean()\n","\n","  print(\"Weather Wind Speed Columns Missing\",sum(weather_data[\"Wind Spd (km/h)\"].isna()),\"values\")\n","  weather_data[\"Wind Spd (km/h)\"][weather_data[\"Wind Spd (km/h)\"].isna()] = weather_data[\"Wind Spd (km/h)\"].mean()\n","\n","  print(\"Weather Visibility Missing\",sum(weather_data[\"Visibility (km)\"].isna()),\"values\")\n","  weather_data[\"Visibility (km)\"][weather_data[\"Visibility (km)\"].isna()] = weather_data[\"Visibility (km)\"].mean()\n","\n","  print(\"Weather Time/Date Missing\",sum(weather_data.index.to_series().isna()),\"values\")\n","  weather_data[\"Visibility (km)\"][weather_data[\"Visibility (km)\"].isna()] = weather_data[\"Visibility (km)\"].mean()\n","\n","  # merge data\n","  bike_data = bike_data.merge(weather_data, left_index=True,right_index=True,indicator=True)\n","  #print(bike_data.head(5))\n","  bike_data = bike_data.drop(columns=[\"_merge\"])\n","\n","\n","\n","  return bike_data\n","\n"],"metadata":{"id":"hLh35ObwH1kc","executionInfo":{"status":"ok","timestamp":1670450104677,"user_tz":300,"elapsed":5,"user":{"displayName":"Ray Coden Mercurius","userId":"17162744304693628162"}}},"execution_count":257,"outputs":[]},{"cell_type":"code","source":["def remove_yearly_trend(bike_data):\n","  '''Attempts to remove the year-on-year growth trend to make prediction easier'''\n","  '''Not statistically valid. Contains data leakage since trend removal occurs before train-test split, and hence its calibrated\n","     with test-data'''\n","  temp_data = bike_data.copy()\n","  temp_data[\"num_trips\"] = temp_data[\"num_trips\"]*(1-temp_data[\"Years Since Start\"]*0.6)\n","  plot_data = temp_data.groupby(temp_data.index.to_series().dt.round(\"30D\")).agg({'num_trips':'sum'})\n","  plt.plot(temp_data)\n","  plt.show()\n","\n","  bike_data[\"num_trips\"] = temp_data[\"num_trips\"]\n","\n","  return bike_data"],"metadata":{"id":"eq8tYWTjFt8E","executionInfo":{"status":"ok","timestamp":1670450104677,"user_tz":300,"elapsed":5,"user":{"displayName":"Ray Coden Mercurius","userId":"17162744304693628162"}}},"execution_count":258,"outputs":[]},{"cell_type":"code","source":["def convert_continuous_to_discrete(data):\n","  '''Converts continous time features (ex. Day of week ∈[0,7]) into binary classifications (ex. IsMonday∈{0,1}, IsTuesday∈{0,1}) to help linear\n","      regression better fit non-linear time trends'''\n","  data = data.copy()\n","  time = data.index.to_series()\n","  data = pd.concat([data,pd.get_dummies(time.dt.month.astype(\"string\"), prefix='Month')], axis=1)\n","  data = pd.concat([data,pd.get_dummies(time.dt.hour.astype(\"string\"), prefix='Hour')], axis=1)\n","  data = pd.concat([data,pd.get_dummies(time.dt.dayofweek.astype(\"string\"), prefix='Weekday')], axis=1)\n","\n","  data = data.drop(columns=[\"Day of Year\",\"Day of Week\",\"Hour of Day\"])\n","\n","  # Add missing categories in case not encountered\n","  for i in range(0,13):\n","    col = \"Month_\"+str(i)\n","    if(col not in data.columns):\n","      data[col] = np.zeros(len(data))\n","  for i in range(0,25):\n","    col = \"Hour_\"+str(i)\n","    if(col not in data.columns):\n","      data[col] = np.zeros(len(data))\n","  for i in range(0,7):\n","    col = \"Weekday_\"+str(i)\n","    if(col not in data.columns):\n","      data[col] = np.zeros(len(data))\n","\n","  data = data.sort_index(axis=1)\n","  #print(data.head(5))\n","\n","  return data.copy()"],"metadata":{"id":"By-Orb2b0kWv","executionInfo":{"status":"ok","timestamp":1670450104677,"user_tz":300,"elapsed":5,"user":{"displayName":"Ray Coden Mercurius","userId":"17162744304693628162"}}},"execution_count":259,"outputs":[]},{"cell_type":"code","source":["#sns.boxplot(x=X_data[\"Snow\"], y=Y_data,showfliers=False)\n","#plt.show()\n","#plt.scatter(X_data[\"Visibility (km)\"], Y_data,s=3)"],"metadata":{"id":"88yzJ26n6Kvk","executionInfo":{"status":"ok","timestamp":1670450104678,"user_tz":300,"elapsed":5,"user":{"displayName":"Ray Coden Mercurius","userId":"17162744304693628162"}}},"execution_count":260,"outputs":[]},{"cell_type":"code","source":["def get_historical_data(date_range,year_range,X_train,Y_train,X_test):\n","  '''Returns filtered train data, to only include dates at a similar time of year to valid/test range'''\n","  '''Reduces the requirement for model to understand seasonal trends'''\n","  '''For example if predicting in Sepetember 2022, return train data with only Sep 2021, Sep 2020, Sep 2019 etc...'''\n","  days = int((date_range-14)/2)\n","\n","  filt = np.zeros(len(X_train))\n","  # For loop runs back from 0 to specified number of years before present\n","  for years in range(0,10):\n","      if(years>year_range):\n","        continue\n","      # lower and upper specify the valid date range for each year\n","      lower = X_test.index.to_series().min() - pd.DateOffset(years=years) - pd.DateOffset(days=days)\n","      upper = X_test.index.to_series().max() - pd.DateOffset(years=years) + pd.DateOffset(days=days)\n","      #print(\"Upper\",upper,\"\\nLower\",lower)\n","      temp_filt = (X_train.index.to_series()>=lower) & (X_train.index.to_series()<=upper)\n","      filt = filt | temp_filt\n","\n","  X_new = X_train[filt].copy()\n","  Y_new = Y_train[filt].copy()\n","\n","  #print(\"Filtered Historical Data\",X_new.index.to_series(),Y_new.index.to_series())\n","  return X_new, Y_new \n"],"metadata":{"id":"OumcOu7AEYEz","executionInfo":{"status":"ok","timestamp":1670450104678,"user_tz":300,"elapsed":5,"user":{"displayName":"Ray Coden Mercurius","userId":"17162744304693628162"}}},"execution_count":261,"outputs":[]},{"cell_type":"code","source":["def load_train_data(weather_info=False,remove_yearly_trend=False):\n","  '''The master function that runs the entire pre-processing pipeline'''\n","  '''Calls all the othe preprocessing functions'''\n","  # load bicycle usage and weather information\n","  bike_data = load_bike_data()\n","  bike_data = drop_features(bike_data,keep_columns = [\"num_trips\"], remove_columns=None)\n","  print(\"\\n\\nBike Data:\",bike_data.tail(5))\n","  weather_data = load_weather_data()\n","  print(\"\\n\\nWeather Data:\",weather_data.tail(5))\n","\n","  # add temporal features\n","  bike_data = add_temporal_features(bike_data)\n","\n","  # choose whether to add weather features and/or remove the yearly growth trend\n","  if(weather_info):\n","    bike_data = add_weather_features(bike_data,weather_data)\n","  if(remove_yearly_trend):\n","    bike_data = remove_yearly_trend(bike_data)\n","\n","  bike_data = bike_data.sort_index()\n","  Y_data = bike_data[\"num_trips\"].copy()\n","  X_data = bike_data.drop(columns=[\"num_trips\"])\n","\n","  return X_data,Y_data\n"],"metadata":{"id":"GADwG0ENX4ap","executionInfo":{"status":"ok","timestamp":1670450104678,"user_tz":300,"elapsed":5,"user":{"displayName":"Ray Coden Mercurius","userId":"17162744304693628162"}}},"execution_count":262,"outputs":[]},{"cell_type":"code","source":["def train_model(X,Y,model,test=False):\n","  '''Trains the specified model and produces results with time-series cross validation split'''\n","  '''If test=False, it will show evaluation results on valid data. Else, it tests performs evaluation on test data'''\n","  rmse = []\n","  MAE = []\n","  MAPE = []\n","  r2 = []\n","\n","  # here we specifiy the size of the test and valid portions, (1 week each, so both in total get 2 weeks * 7 days/week * 24 hours/day datapoints)\n","  # to cover the whole year we need 365/(2*7) = 26 splits\n","  tss = TimeSeriesSplit(test_size = 2*7*24,n_splits=26)\n","  ind = 0\n","  Y_test_stacked = pd.Series()\n","  Y_pred_stacked = pd.Series()\n","\n","  # The cross validation looop\n","  for train_index, test_index in tss.split(X):\n","      ind+=1\n","      # Instead of 26 splits I resampled 8 evenly spaced splits to save compute time.\n","      if((ind)%3!=0):\n","        continue\n","\n","      # Select to evaluate on test or valid data.\n","      # Our test/valid split is 2 weeks long. First week is valid, second week is test.\n","      if(test==True):\n","        test_index = test_index[0:len(test_index)//2]\n","      else:\n","        test_index = test_index[len(test_index)//2:]\n","\n","      X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","      Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n","\n","      print(\"\\nTrain Range:\",X_train.index.min(),\"  \",X_train.index.max())\n","      print(\"Test Range:\",X_test.index.min(),\"  \",X_test.index.max())\n","\n","\n","      Y_pred = None\n","      if(model==None):\n","          continue\n","\n","      if(model==\"Random Forest\"):\n","          rf = RandomForestRegressor(random_state=0,max_depth=10)\n","          rf.fit(X_train,Y_train)\n","          Y_pred = rf.predict(X_test)\n","      \n","      if(model==\"Linear Regression\"):\n","          X_train_temp = X_train; Y_train_temp = Y_train;\n","          X_train_temp, Y_train_temp = get_historical_data(60,100, X_train, Y_train, X_test)\n","          X_train_temp = convert_continuous_to_discrete(X_train_temp)\n","          lr = LinearRegression().fit(X_train_temp, Y_train_temp)\n","          X_test_temp = convert_continuous_to_discrete(X_test)\n","          #print(X_train_temp.head(5))\n","          #print(X_test_temp.head(5))\n","          Y_pred = lr.predict(X_test_temp)\n","      \n","      if(model==\"Facebook Prophet\"):\n","          fp = Prophet()\n","\n","          # format data for facebook prophet\n","          X_train[\"ds\"] = X_train.index.to_series().dt.tz_convert(None).copy()\n","          X_train = X_train.reset_index(drop=True)[[\"ds\"]]\n","          X_train[\"y\"] = Y_train.reset_index(drop=True)\n","          X_test[\"ds\"] = X_test.index.to_series().dt.tz_convert(None).copy()\n","          X_test  = X_test.reset_index(drop=True)[[\"ds\"]]\n","\n","          fp.fit(X_train)\n","          Y_pred = fp.predict(X_test)\n","          Y_pred = Y_pred[\"yhat\"].copy().reset_index(drop=True)\n","      Y_pred = pd.Series(Y_pred)\n","          \n","      \n","      #rmse = mean_squared_error(Y_test,Y_pred,squared=False)\n","      #MAE = mean_absolute_error(Y_test,Y_pred)\n","      #MAPE =mean_absolute_percentage_error(Y_test,Y_pred)\n","      #r2 = r2_score(Y_test,Y_pred)\n","\n","      #temp_df = pd.DataFrame()\n","      #temp_df[\"Truth\"] = Y_test.copy().reset_index(drop=True)\n","      #temp_df[\"Predictions\"] = Y_pred\n","      #temp_df.index = X_test.index\n","      #print(temp_df.head(100))\n","      #print(\"\\n\",temp_df.head(10))\n","      #print(\"\\nModel:\",model)\n","      #print(\"RMSE:\",rmse)\n","      #print(\"MAE:\",MAE)\n","      #print(\"MAPE:\",MAPE)\n","      #print(\"R2:\",r2)\n","\n","      Y_test_stacked = pd.concat([Y_test_stacked,Y_test])\n","      Y_pred_stacked = pd.concat([Y_pred_stacked,Y_pred])\n","\n","\n","\n","  print(\"\\nModel:\",model)\n","  print(\"RMSE:\",mean_squared_error(Y_test_stacked,Y_pred_stacked,squared=False))\n","  print(\"MAE:\",mean_absolute_error(Y_test_stacked,Y_pred_stacked))\n","  print(\"MAPE:\",mean_absolute_percentage_error(Y_test_stacked,Y_pred_stacked))\n","  print(\"R2:\",r2_score(Y_test_stacked,Y_pred_stacked))\n"],"metadata":{"id":"x4bViWmuwh_I","executionInfo":{"status":"ok","timestamp":1670450104678,"user_tz":300,"elapsed":5,"user":{"displayName":"Ray Coden Mercurius","userId":"17162744304693628162"}}},"execution_count":263,"outputs":[]},{"cell_type":"code","source":["# load and preproces data\n","X_data, Y_data = load_train_data(weather_info=False,remove_yearly_trend=False)\n","model = \"Random Forest\"\n","if(model==\"Linear Regression\"):\n","  print(\"\\n\\nX data:\",convert_continuous_to_discrete(X_data).head())\n","else:\n","  print(\"\\n\\nX data:\",X_data.head())\n","# train and evaluate model\n","train_model(X_data,Y_data,model=model, test=True)"],"metadata":{"id":"XWOSOls61fYP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_latest_predictions(X, Y):\n","  '''Trains every model on the full dataset(except for last week), and returns their predictions for the last week'''\n","  '''This is strictly for intuitive visualization purposes, not evaluation'''\n","  tss = TimeSeriesSplit(test_size = 2*7*24,n_splits=26)\n","  ind = 0\n","\n","  # predictions of each model\n","  Y_rf = None; Y_lr= None; Y_fp = None; fp = None;\n","  for train_index, test_index in tss.split(X_data):\n","      ind+=1\n","      # skip all the splits except for the very last one\n","      if(ind!=26):\n","        continue\n","\n","      X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","      Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n","\n","      print(\"\\nTrain Range:\",X_train.index.min(),\"  \",X_train.index.max())\n","      print(\"Test Range:\",X_test.index.min(),\"  \",X_test.index.max())\n","\n","      # Linear Regression\n","      X_train_temp = X_train.copy(); Y_train_temp = Y_train.copy()\n","      #X_train_hist, Y_train_hist = get_historical_data(60,100, X_train_temp, Y_train_temp, X_test)\n","      X_train_temp = convert_continuous_to_discrete(X_train_temp)\n","      lr = LinearRegression().fit(X_train_temp, Y_train_temp)\n","      X_test_temp = convert_continuous_to_discrete(X_test)\n","      Y_lr = lr.predict(X_test_temp)\n","\n","      # Random Forest\n","      rf = RandomForestRegressor(random_state=0)\n","      rf.fit(X_train,Y_train)\n","      Y_rf = rf.predict(X_test)\n","      \n","      # Facebook Prophet\n","      fp = Prophet()\n","      # format data for facebook prophet\n","      X_train[\"ds\"] = X_train.index.to_series().dt.tz_convert(None).copy()\n","      X_train = X_train.reset_index(drop=True)[[\"ds\"]]\n","      X_train[\"y\"] = Y_train.reset_index(drop=True)\n","      X_test[\"ds\"] = X_test.index.to_series().dt.tz_convert(None).copy()\n","      X_test  = X_test.reset_index(drop=True)[[\"ds\"]]\n","      # Predict\n","      fp.fit(X_train)\n","      Y_fp = fp.predict(X_test)\n","    \n","  return Y_rf, Y_lr, Y_fp, Y_test, fp"],"metadata":{"id":"zxxIMS1oXYHJ","executionInfo":{"status":"aborted","timestamp":1670449343131,"user_tz":300,"elapsed":4,"user":{"displayName":"Ray Coden Mercurius","userId":"17162744304693628162"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_predictions(Y_rf, Y_lr, Y_fp, Y_test, fp):\n","    '''Creates Intuitive plot each model's predictions over several days'''\n","\n","    fig = fp.plot(Y_fp)\n","    ax = fig.gca()\n","    ax.set_xlim([pd.Timestamp('2022-08-28',tz=\"EST\"), pd.Timestamp('2022-08-31',tz=\"EST\")])\n","    ax.set_ylim([0, 2750])\n","\n","    Y_rf = pd.Series(Y_rf)\n","    Y_rf.index = Y_fp[\"ds\"]\n","    plt.plot(Y_rf,color='green',label=\"Random Forest\")\n","\n","    Y_lr = pd.Series(Y_lr)\n","    Y_lr.index =Y_fp[\"ds\"]\n","    plt.plot(Y_lr,color='yellow',label=\"Linear Regression\")\n","\n","    Y_test = pd.Series(Y_test)\n","    Y_test.index = Y_fp[\"ds\"]\n","    plt.plot(Y_test,color='black', linewidth=4,label=\"Observed\")\n","\n","    L=plt.legend()\n","    L.get_texts()[1].set_text('make it short')\n","\n","    plt.legend([\"\",\"Facebook Prophet\",\"Random Forest\",\"Linear Regression\",\"Observed\"])\n","    plt.xlabel(\"Time (Day-Month-Hour)\")\n","    plt.ylabel(\"Number of Trips\")\n","    plt.title(\"Predictions with only Time Info\",fontsize=20)\n","    plt.show()"],"metadata":{"id":"PPPNPChTfnGy","executionInfo":{"status":"aborted","timestamp":1670449343131,"user_tz":300,"elapsed":4,"user":{"displayName":"Ray Coden Mercurius","userId":"17162744304693628162"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_residuals(Y_rf, Y_lr, Y_fp, Y_test, fp):\n","  '''Plots the residual errors of each model'''\n","  plt.scatter(Y_rf,Y_test-Y_rf,s=15)\n","  plt.title(\"Random Forest Residuals\")\n","  plt.ylim([-900,1350])\n","  plt.axhline(y=0.5, color='black', linestyle='-')\n","  plt.xlabel(\"Y Predicted\")\n","  plt.ylabel(\"Y Truth - Y Predicted\")\n","  plt.show()\n","\n","  plt.scatter(Y_lr,Y_test-Y_lr,s=15)\n","  plt.title(\"Linear Regression Residuals\")\n","  plt.ylim([-900,1350])\n","  plt.axhline(y=0.5, color='black', linestyle='-')\n","  plt.xlabel(\"Y Predicted\")\n","  plt.ylabel(\"Y Truth - Y Predicted\")\n","  plt.show()\n","\n","  Y_fp = Y_fp[\"yhat\"].to_numpy()\n","  print(Y_fp.size)\n","  print(Y_test.size)\n","  plt.scatter(Y_fp,Y_test-Y_fp,s=15)\n","  plt.title(\"Facebook Prophet Residuals\")\n","  plt.ylim([-900,1350])\n","  plt.axhline(y=0.5, color='black', linestyle='-')\n","  plt.xlabel(\"Y Predicted\")\n","  plt.ylabel(\"Y Truth - Y Predicted\")\n","  plt.show()\n"],"metadata":{"id":"TahqxJRhBhG1","executionInfo":{"status":"aborted","timestamp":1670449343131,"user_tz":300,"elapsed":4,"user":{"displayName":"Ray Coden Mercurius","userId":"17162744304693628162"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create plots for each models\n","X_data, Y_data = load_train_data(weather_info=False,remove_yearly_trend=False)\n","Y_rf, Y_lr, Y_fp, Y_test, fp = get_latest_predictions(X_data, Y_data)\n","plot_predictions(Y_rf, Y_lr, Y_fp, Y_test, fp)\n","plot_residuals(Y_rf, Y_lr, Y_fp, Y_test, fp)"],"metadata":{"id":"ZRAooXYsZfXx"},"execution_count":null,"outputs":[]}]}